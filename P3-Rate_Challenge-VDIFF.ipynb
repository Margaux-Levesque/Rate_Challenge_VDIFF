{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RATE CHALLENGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectifs : \n",
    "\n",
    "Le projet peut √™tre d√©coup√© en quatre √©tapes :\n",
    "\n",
    "Partie 1 : faire une EDA (exploration et analyse data) et les pr√©traitements et entra√Æner un mod√®le de base avec le fichier data_train.csv\n",
    "\n",
    "Partie 2 : am√©liorez le score f1 de votre mod√®le sur votre ensemble de test (vous pouvez essayer l'ing√©nierie de fonctionnalit√©s, la s√©lection de fonctionnalit√©s, la r√©gularisation, les mod√®les non lin√©aires, l'optimisation d'hyperparam√®tres par recherche de grille, etc...)\n",
    "\n",
    "Partie 3 : Une fois que vous √™tes satisfait du score de votre mod√®le, vous pouvez l'utiliser pour faire des pr√©dictions avec le fichier data_test.csv . Vous devrez vider les pr√©dictions dans un fichier .csv qui sera envoy√© √† Kaggle (en fait, √† votre professeur/TA ü§ì). Vous pouvez faire autant de soumissions que vous le souhaitez, n'h√©sitez pas √† essayer diff√©rents mod√®les !\n",
    "\n",
    "Partie 4 : Prenez le temps d'analyser les param√®tres de votre meilleur mod√®le. Existe-t-il des leviers d'action permettant d'am√©liorer le taux de conversion de la newsletter ? Quelles recommandations feriez-vous √† l'√©quipe ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I) T√©l√©chargement de la librairy Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.8/site-packages (4.8.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from plotly) (1.15.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.8/site-packages (from plotly) (1.3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II) Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "# setting Jedha color palette as default\n",
    "pio.templates[\"jedha\"] = go.layout.Template(\n",
    "    layout_colorway=[\"#4B9AC7\", \"#4BE8E0\", \"#9DD4F3\", \"#97FBF6\", \"#2A7FAF\", \"#23B1AB\", \"#0E3449\", \"#015955\"]\n",
    ")\n",
    "pio.templates.default = \"jedha\"\n",
    "pio.renderers.default = \"iframe_connected\" # to be replaced by \"iframe\" if working on JULIE\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III) Lire le fichier data_train : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set with labels (our train+test) : (284580, 6)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('conversion_data_train.csv')\n",
    "print('Set with labels (our train+test) :', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows : 284580\n",
      "\n",
      "Display of dataset: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Seo</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  age  new_user  source  total_pages_visited  converted\n",
       "0    China   22         1  Direct                    2          0\n",
       "1       UK   21         1     Ads                    3          0\n",
       "2  Germany   20         0     Seo                   14          1\n",
       "3       US   23         1     Seo                    3          0\n",
       "4       US   28         1  Direct                    3          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basics statistics: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284580</td>\n",
       "      <td>284580.000000</td>\n",
       "      <td>284580.000000</td>\n",
       "      <td>284580</td>\n",
       "      <td>284580.000000</td>\n",
       "      <td>284580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>160124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30.564203</td>\n",
       "      <td>0.685452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.873252</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.266789</td>\n",
       "      <td>0.464336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.341995</td>\n",
       "      <td>0.176685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country            age       new_user  source  total_pages_visited  \\\n",
       "count   284580  284580.000000  284580.000000  284580        284580.000000   \n",
       "unique       4            NaN            NaN       3                  NaN   \n",
       "top         US            NaN            NaN     Seo                  NaN   \n",
       "freq    160124            NaN            NaN  139477                  NaN   \n",
       "mean       NaN      30.564203       0.685452     NaN             4.873252   \n",
       "std        NaN       8.266789       0.464336     NaN             3.341995   \n",
       "min        NaN      17.000000       0.000000     NaN             1.000000   \n",
       "25%        NaN      24.000000       0.000000     NaN             2.000000   \n",
       "50%        NaN      30.000000       1.000000     NaN             4.000000   \n",
       "75%        NaN      36.000000       1.000000     NaN             7.000000   \n",
       "max        NaN     123.000000       1.000000     NaN            29.000000   \n",
       "\n",
       "            converted  \n",
       "count   284580.000000  \n",
       "unique            NaN  \n",
       "top               NaN  \n",
       "freq              NaN  \n",
       "mean         0.032258  \n",
       "std          0.176685  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          0.000000  \n",
       "max          1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage of missing values: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "country                0.0\n",
       "age                    0.0\n",
       "new_user               0.0\n",
       "source                 0.0\n",
       "total_pages_visited    0.0\n",
       "converted              0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic stats\n",
    "print(\"Number of rows : {}\".format(data.shape[0]))\n",
    "print()\n",
    "\n",
    "print(\"Display of dataset: \")\n",
    "display(data.head())\n",
    "print()\n",
    "\n",
    "print(\"Basics statistics: \")\n",
    "data_desc = data.describe(include='all')\n",
    "display(data_desc)\n",
    "print()\n",
    "\n",
    "print(\"Percentage of missing values: \")\n",
    "display(100*data.isnull().sum()/data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyse du Dataset : \n",
    "- Aucunes valeurs manquantes \n",
    "- La target (y) converted est une donn√©e qualitative d√©j√† encod√©e en 0 et 1\n",
    "- les features (X) :\n",
    "    - qualitative : country, source et new_user (d√©j√† encod√©e en 0 et 1)\n",
    "    - quantitative : age, total_pages_visited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV) Selectionner une partie du dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is quite big : you must create a sample of the dataset before making any visualizations !\n",
    "data_sample = data.sample(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V) Cr√©er un mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choisissez les variables √† utiliser dans le mod√®le et cr√©ez les ensembles de formation et de test.\n",
    "D'apr√®s l'EDA, nous savons que la caract√©ristique la plus utile est : total_pages_visited. \n",
    "Cr√©ons un mod√®le de base, en utilisant d'abord seulement cette caract√©ristique : dans les prochaines cellules, nous ferons des pr√©traitements et entra√Ænerons une r√©gression logistique simple (univari√©e)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['country','age','new_user','source','total_pages_visited']\n",
    "target_variable = 'converted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanatory variables :  Index(['country', 'age', 'new_user', 'source', 'total_pages_visited'], dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data_sample.loc[:, features_list]\n",
    "Y = data_sample.loc[:, target_variable]\n",
    "\n",
    "print('Explanatory variables : ', X.columns)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divide dataset Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify = Y)\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert pandas DataFrames to numpy arrays...\n",
      "...Done\n",
      "[['China' 51 1 'Ads' 6]\n",
      " ['China' 29 1 'Direct' 4]\n",
      " ['UK' 33 0 'Ads' 4]\n",
      " ['UK' 37 0 'Seo' 9]\n",
      " ['US' 26 1 'Direct' 4]]\n",
      "[['US' 29 1 'Ads' 5]\n",
      " ['Germany' 24 1 'Seo' 4]]\n",
      "\n",
      "[0 0 0 0 0]\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "Y_train = Y_train.values\n",
    "Y_test = Y_test.values\n",
    "print(\"...Done\")\n",
    "\n",
    "print(X_train[0:5,:])\n",
    "print(X_test[0:2,:])\n",
    "print()\n",
    "print(Y_train[0:5])\n",
    "print(Y_test[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training et Test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put here all the preprocessings\n",
    "#print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "#Features qualitative (country, source) et :\n",
    "categorical_features = [0,3]                 # Positions of categorical columns in X_train/X_test\n",
    "categorical_transformer = OneHotEncoder(drop='first') \n",
    "\n",
    "\n",
    "# Features quantitatives (age, new_user, total_page_visited)\n",
    "numeric_features = [1,4,2]                     # Positions of numeric columns in X_train/X_test\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appliquer le pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing preprocessings on train set...\n",
      "[['China' 51 1 'Ads' 6]\n",
      " ['China' 29 1 'Direct' 4]\n",
      " ['UK' 33 0 'Ads' 4]\n",
      " ['UK' 37 0 'Seo' 9]\n",
      " ['US' 26 1 'Direct' 4]]\n",
      "...Done.\n",
      "[[ 2.44967081  0.32227374  0.68363106  0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [-0.1873966  -0.26993711  0.68363106  0.          0.          0.\n",
      "   1.          0.        ]\n",
      " [ 0.2920702  -0.26993711 -1.4627773   0.          1.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.771537    1.21059001 -1.4627773   0.          1.          0.\n",
      "   0.          1.        ]\n",
      " [-0.5469967  -0.26993711  0.68363106  0.          0.          1.\n",
      "   1.          0.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessings on train set\n",
    "print(\"Performing preprocessings on train set...\")\n",
    "print(X_train[0:5,:])\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "print('...Done.')\n",
    "print(X_train[0:5,:])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing preprocessings on test set...\n",
      "[['US' 29 1 'Ads' 5]\n",
      " ['Germany' 24 1 'Seo' 4]\n",
      " ['US' 31 1 'Seo' 2]\n",
      " ['US' 19 0 'Seo' 2]\n",
      " ['US' 20 1 'Ads' 4]]\n",
      "...Done.\n",
      "[[-0.1873966   0.02616832  0.68363106  0.          0.          1.\n",
      "   0.          0.        ]\n",
      " [-0.78673011 -0.26993711  0.68363106  1.          0.          0.\n",
      "   0.          1.        ]\n",
      " [ 0.0523368  -0.86214795  0.68363106  0.          0.          1.\n",
      "   0.          1.        ]\n",
      " [-1.38606361 -0.86214795 -1.4627773   0.          0.          1.\n",
      "   0.          1.        ]\n",
      " [-1.26619691 -0.26993711  0.68363106  0.          0.          1.\n",
      "   0.          0.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessings on test set\n",
    "print(\"Performing preprocessings on test set...\")\n",
    "print(X_test[0:5,:])\n",
    "X_test = preprocessor.transform(X_test) \n",
    "print('...Done.')\n",
    "print(X_test[0:5,:])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model...\n",
      "...Done.\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Train model...\")\n",
    "classifier = LogisticRegression()  \n",
    "classifier.fit(X_train, Y_train)\n",
    "print(\"...Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction sur le train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = classifier.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction sur le test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_test_pred = classifier.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score on train set :  0.7685774946921445\n",
      "f1-score on test set :  0.7678571428571428\n"
     ]
    }
   ],
   "source": [
    "# WARNING : Use the same score as the one that will be used by Kaggle !\n",
    "# Here, the f1-score will be used to assess the performances on the leaderboard\n",
    "print(\"f1-score on train set : \", f1_score(Y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on train set : \n",
      "[[7710   32]\n",
      " [  77  181]]\n",
      "\n",
      "Confusion matrix on test set : \n",
      "[[1931    4]\n",
      " [  22   43]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can also check more performance metrics to better understand what your model is doing\n",
    "print(\"Confusion matrix on train set : \")\n",
    "print(confusion_matrix(Y_train, Y_train_pred))\n",
    "print()\n",
    "print(\"Confusion matrix on test set : \")\n",
    "print(confusion_matrix(Y_test, Y_test_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essayer d'utiliser le modele sur le dataset au complet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de faire des pr√©dictions sur le fichier conversion_data_test.csv, entra√Ænons notre mod√®le sur TOUTES les donn√©es qui se trouvaient dans conversion_data_train.csv. \n",
    "\n",
    "Parfois, cela permet d'apporter de petites am√©liorations au score car nous utilisons plus d'exemples pour entra√Æner le mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['country','age','new_user','source','total_pages_visited']\n",
    "target_variable = 'converted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanatory variables :  Index(['country', 'age', 'new_user', 'source', 'total_pages_visited'], dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Faire l'entrainement sur toutes les donn√©es au complet du train\n",
    "X = data.loc[:, features_list]\n",
    "Y = data.loc[:, target_variable]\n",
    "\n",
    "print('Explanatory variables : ', X.columns)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divide dataset Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify = Y)\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert pandas DataFrames to numpy arrays...\n",
      "...Done\n",
      "[['China' 19 1 'Seo' 1]\n",
      " ['US' 33 1 'Direct' 5]\n",
      " ['US' 51 1 'Ads' 2]\n",
      " ['China' 17 0 'Seo' 1]\n",
      " ['China' 28 1 'Seo' 5]]\n",
      "[['UK' 34 1 'Ads' 1]\n",
      " ['UK' 32 0 'Ads' 5]]\n",
      "\n",
      "[0 0 0 0 0]\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "Y_train = Y_train.values\n",
    "Y_test = Y_test.values\n",
    "print(\"...Done\")\n",
    "\n",
    "print(X_train[0:5,:])\n",
    "print(X_test[0:2,:])\n",
    "print()\n",
    "print(Y_train[0:5])\n",
    "print(Y_test[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put here all the preprocessings\n",
    "#print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "#Features qualitative (country, source) et :\n",
    "categorical_features = [0,3]                 # Positions of categorical columns in X_train/X_test\n",
    "categorical_transformer = OneHotEncoder(drop='first') \n",
    "\n",
    "\n",
    "# Features quantitatives (age, new_user, total_page_visited)\n",
    "numeric_features = [1,4,2]                     # Positions of numeric columns in X_train/X_test\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing preprocessings on train set...\n",
      "[['China' 19 1 'Seo' 1]\n",
      " ['US' 33 1 'Direct' 5]\n",
      " ['US' 51 1 'Ads' 2]\n",
      " ['China' 17 0 'Seo' 1]\n",
      " ['China' 28 1 'Seo' 5]]\n",
      "...Done.\n",
      "[[-1.3990984  -1.15935344  0.67651656  0.          0.          0.\n",
      "   0.          1.        ]\n",
      " [ 0.29299544  0.03743241  0.67651656  0.          0.          1.\n",
      "   1.          0.        ]\n",
      " [ 2.46854467 -0.86015697  0.67651656  0.          0.          1.\n",
      "   0.          0.        ]\n",
      " [-1.64082609 -1.15935344 -1.47816042  0.          0.          0.\n",
      "   0.          1.        ]\n",
      " [-0.31132378  0.03743241  0.67651656  0.          0.          0.\n",
      "   0.          1.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessings on train set\n",
    "print(\"Performing preprocessings on train set...\")\n",
    "print(X_train[0:5,:])\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "print('...Done.')\n",
    "print(X_train[0:5,:])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing preprocessings on test set...\n",
      "[['UK' 34 1 'Ads' 1]\n",
      " ['UK' 32 0 'Ads' 5]\n",
      " ['US' 44 1 'Ads' 1]\n",
      " ['US' 35 1 'Direct' 1]\n",
      " ['US' 29 1 'Direct' 3]]\n",
      "...Done.\n",
      "[[ 0.41385929 -1.15935344  0.67651656  0.          1.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.1721316   0.03743241 -1.47816042  0.          1.          0.\n",
      "   0.          0.        ]\n",
      " [ 1.62249775 -1.15935344  0.67651656  0.          0.          1.\n",
      "   0.          0.        ]\n",
      " [ 0.53472314 -1.15935344  0.67651656  0.          0.          1.\n",
      "   1.          0.        ]\n",
      " [-0.19045994 -0.56096051  0.67651656  0.          0.          1.\n",
      "   1.          0.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessings on test set\n",
    "print(\"Performing preprocessings on test set...\")\n",
    "print(X_test[0:5,:])\n",
    "X_test = preprocessor.transform(X_test) \n",
    "print('...Done.')\n",
    "print(X_test[0:5,:])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Attention le mod√®le est d√©j√† entrainer donc on peut passer √† l'√©tape de la pr√©diction\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = classifier.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_test_pred = classifier.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score on train set :  0.7601641178664678\n",
      "f1-score on test set :  0.751269035532995\n"
     ]
    }
   ],
   "source": [
    "# WARNING : Use the same score as the one that will be used by Kaggle !\n",
    "# Here, the f1-score will be used to assess the performances on the leaderboard\n",
    "print(\"f1-score on train set : \", f1_score(Y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on train set : \n",
      "[[219354    966]\n",
      " [  2249   5095]]\n",
      "\n",
      "Confusion matrix on test set : \n",
      "[[54825   255]\n",
      " [  578  1258]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can also check more performance metrics to better understand what your model is doing\n",
    "print(\"Confusion matrix on train set : \")\n",
    "print(confusion_matrix(Y_train, Y_train_pred))\n",
    "print()\n",
    "print(\"Confusion matrix on test set : \")\n",
    "print(confusion_matrix(Y_test, Y_test_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB : Dans notre cas, le F1 score a l√©g√©rement baisser mais reste n√©anmoins stable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III) Lire le fichier data_test : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction set (without labels) : (31620, 5)\n"
     ]
    }
   ],
   "source": [
    "# Read data without labels\n",
    "data_without_labels = pd.read_csv('conversion_data_test.csv')\n",
    "print('Prediction set (without labels) :', data_without_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows : 31620\n",
      "\n",
      "Display of dataset: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>Seo</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>Seo</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  age  new_user  source  total_pages_visited\n",
       "0      UK   28         0     Seo                   16\n",
       "1      UK   22         1  Direct                    5\n",
       "2   China   32         1     Seo                    1\n",
       "3      US   32         1     Ads                    6\n",
       "4   China   25         0     Seo                    3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basics statistics: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31620</td>\n",
       "      <td>31620.000000</td>\n",
       "      <td>31620.000000</td>\n",
       "      <td>31620</td>\n",
       "      <td>31620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>17968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15563</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30.620746</td>\n",
       "      <td>0.685579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.870398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.316736</td>\n",
       "      <td>0.464292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.333128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country           age      new_user source  total_pages_visited\n",
       "count    31620  31620.000000  31620.000000  31620         31620.000000\n",
       "unique       4           NaN           NaN      3                  NaN\n",
       "top         US           NaN           NaN    Seo                  NaN\n",
       "freq     17968           NaN           NaN  15563                  NaN\n",
       "mean       NaN     30.620746      0.685579    NaN             4.870398\n",
       "std        NaN      8.316736      0.464292    NaN             3.333128\n",
       "min        NaN     17.000000      0.000000    NaN             1.000000\n",
       "25%        NaN     24.000000      0.000000    NaN             2.000000\n",
       "50%        NaN     30.000000      1.000000    NaN             4.000000\n",
       "75%        NaN     36.000000      1.000000    NaN             7.000000\n",
       "max        NaN     69.000000      1.000000    NaN            26.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage of missing values: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "country                0.0\n",
       "age                    0.0\n",
       "new_user               0.0\n",
       "source                 0.0\n",
       "total_pages_visited    0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic stats\n",
    "print(\"Number of rows : {}\".format(data_without_labels.shape[0]))\n",
    "print()\n",
    "\n",
    "print(\"Display of dataset: \")\n",
    "display(data_without_labels.head())\n",
    "print()\n",
    "\n",
    "print(\"Basics statistics: \")\n",
    "data_desc1 = data_without_labels.describe(include='all')\n",
    "display(data_desc1)\n",
    "print()\n",
    "\n",
    "print(\"Percentage of missing values: \")\n",
    "display(100*data_without_labels.isnull().sum()/data_without_labels.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyse du Dataset : \n",
    "- Aucunes valeurs manquantes \n",
    "- La target (y) converted est √† rajouter dans le tableau + c'est une donn√©e qualitative qui sera √† mettre en 1 ou 0\n",
    "- les features (X) :\n",
    "    - qualitative : country, source et new_user (d√©j√† encod√©e en 0 et 1)\n",
    "    - quantitative : age, total_pages_visited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV) Selectionner une partie du dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is quite big : you must create a sample of the dataset before making any visualizations !\n",
    "data_sample1 = data_without_labels.sample(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V) d√©finir les features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning : check consistency of features_list (must be the same than the features \n",
    "# used by your best classifier)\n",
    "features_list = ['country','age','new_user','source','total_pages_visited']\n",
    "\n",
    "X_without_labels = data_without_labels.loc[:, features_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert pandas DataFrames to numpy arrays...\n",
      "...Done\n",
      "[['UK' 28 0 'Seo' 16]\n",
      " ['UK' 22 1 'Direct' 5]\n",
      " ['China' 32 1 'Seo' 1]\n",
      " ['US' 32 1 'Ads' 6]\n",
      " ['China' 25 0 'Seo' 3]]\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X_without_labels= X_without_labels.values\n",
    "print(\"...Done\")\n",
    "\n",
    "print(X_without_labels[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training et Test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put here all the preprocessings\n",
    "#print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "#Features qualitative (country, source) :\n",
    "categorical_features = [0,3]                 # Positions of categorical columns in X_train/X_test\n",
    "categorical_transformer = OneHotEncoder(drop='first') \n",
    "\n",
    "\n",
    "# Features quantitatives (age, total_page_visited, new_user)\n",
    "numeric_features = [1,4,2]                     # Positions of numeric columns in X_train/X_test\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appliquer le pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing preprocessings on train set...\n",
      "[['UK' 28 0 'Seo' 16]\n",
      " ['UK' 22 1 'Direct' 5]\n",
      " ['China' 32 1 'Seo' 1]\n",
      " ['US' 32 1 'Ads' 6]\n",
      " ['China' 25 0 'Seo' 3]]\n",
      "...Done.\n",
      "[[-0.31512217  3.33913917 -1.47663353  0.          1.          0.\n",
      "   0.          1.        ]\n",
      " [-1.03657046  0.03888347  0.6772161   0.          1.          0.\n",
      "   1.          0.        ]\n",
      " [ 0.16584336 -1.16120951  0.6772161   0.          0.          0.\n",
      "   0.          1.        ]\n",
      " [ 0.16584336  0.33890671  0.6772161   0.          0.          1.\n",
      "   0.          0.        ]\n",
      " [-0.67584631 -0.56116302 -1.47663353  0.          0.          0.\n",
      "   0.          1.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessings ON set\n",
    "print(\"Performing preprocessings on train set...\")\n",
    "print(X_without_labels[0:5,:])\n",
    "X_without_labels = preprocessor.fit_transform(X_without_labels)\n",
    "print('...Done.')\n",
    "print(X_without_labels[0:5,:])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction sur le train et test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_without_labels_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5d646897fe55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predictions on training set...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_without_labels_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_without_labels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"...Done.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_without_labels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_without_labels_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Predictions on training set...\")\n",
    "X_without_labels_train = classifier.predict(X_without_labels_train)\n",
    "print(\"...Done.\")\n",
    "print(X_without_labels_train)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predictions on test set\n",
    "print(\"Predictions on training set...\")\n",
    "X_without_labels_test = classifier.predict(X_without_labels_test)\n",
    "print(\"...Done.\")\n",
    "print(X_without_labels_test)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'converted': classifier.predict(X_without_labels)\n",
    "}\n",
    "\n",
    "Y_predictions = pd.DataFrame(columns=['converted'],data=data)\n",
    "\n",
    "Y_predictions.to_csv('conversion_data_test_predictions_Margaux_Levesque.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING : Use the same score as the one that will be used by Kaggle !\n",
    "# Here, the f1-score will be used to assess the performances on the leaderboard\n",
    "print(\"f1-score on train set : \", f1_score(X_without_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion : notre mod√®le n'overfit pas et le score est sup√©rieur √† celui de Kaggle (69% vs 75%). \n",
    "On a pu am√©liorer le score en utilisant tous les features du dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
